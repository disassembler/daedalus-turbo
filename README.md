# Contents
- [About](#about)
- [Requirements](#requirements)
- [Testing it yourself](#testing-it-yourself)
- [Helping spread the word](#helping-spread-the-word)
- [Features](#features)
- [Quality](#quality)
- [Roadmap](#roadmap)
- [Reproducing the benchmarks](#reproducing-the-benchmarks)
- [Performance notes](#performance-notes)

# About
The objective of Daedalus Turbo project is to drastically (>=10x) improve the blockchain synchronization speed of the Daedalus wallet, the primary fully-decentralized wallet of Cardano blockchain.

At the moment, this repository contains an implementation of the highly-parallel wallet-history reconstruction method described in [2023_Sierkov_WalletHistoryReconstruction](./doc/2023_Sierkov_WalletHistoryReconstruction.pdf) paper. As the project moves forward, other components will be added. To better understand the project's scope, read the discussion section of the paper and take a look at the [roadmap](#roadmap).

# Requirements
To test the method on your computer, you'll need:
- A local copy of ImmutableDB generated by Cardano Node. In particular, the *.chunk files are necessary. You should be able to specify a path to it. Normally, one can find ImmutableDB created by Daedalus in one of the following locations:
  - On Windows: %APPDATA%\Daedalus Mainnet\chain\immutable 
  - On Linux: ~/.local/share/Daedalus/mainnet/chain/immutable
  - On Mac: ~/Library/Application Support/Daedalus/mainnet/chain/immutable
- A Docker installation. Ensure that all host's CPUs are available within the container for best performance.
- 20GB of free disk space: 10GB for the created indices and another 10GB for temporary files, which will be deleted once the indices are created.
- 4GB+ of RAM. The precise amount depends on the number of threads that your CPU can handle. 4GB shall be sufficient for up to 20 threads. For 48 threads about 8GB will be needed.
- A Cardano stake address (in BECH32 "stake1XXXXX" format) for which you can verify the list of associated transactions using Daedalus or a blockchain explorer.
- Optional: if you wish to run unit tests and microbenchmarks,
  ensure that [git's LFS plugin](https://git-lfs.com/) is installed. Example data in the [data](./data) directory are managed with it.

# Testing it yourself
Clone this repository and make it your working directory:
```
git clone https://github.com/sierkov/daedalus-turbo.git dt
cd dt
```

Run the following commands to prepare and start a container, replacing:
- */your-immutable* with the path to a copy of ImmutableDB.
- */your-indices* with the location where you'd like the newly built indices to be stored.
```
docker build -t dt -f Dockerfile.test .
docker run -it --rm -v /your-immutable:/data/immutable -v /your-indices:/data/indices dt
```

Within the container's shell run the following commands to create the indices
and perform the transaction-history reconstruction for a given stake key.
The string *stake1XXXXXX* must be replaced with the stake key of your choosing.
```
sudo chown -R dev:dev /data/indices
./create-index /data/immutable /data/indices
./search-index /data/immutable /data/indices stake1XXXXXX
```
The second command will output to the console the list of transactions related to the specified stake key along with their metadata.

N.B.: If the transactions do not match your alternative source, please double check that the copy of the ImmutableDB that you've passed to the command is up to date!

# Helping spread the word
One of the major reasons why Daedalus is so slow is that the founder of Cardano and the CEO of the IOHK, Charles Hoskinson, believes that it's impossible to make it faster.
So, one doesn't invest into what one believes is impossible.

If you're persuaded by the evidence presented here, send him the following tweet:
```
@IOHK_Charles, why Daedalus is still so slow when @TurboDaedalus method exists?
https://github.com/sierkov/daedalus-turbo
```
Changing the beliefs of people is often harder than building top-notch technology.
So, every single message can make a difference. Thank you!

# Features
The current version of the algorithm supports only a minimal set of Cardano features:
- Shelley-era addresses with an explicit stake-key hash (type 1).
- ADA-only transactions.
- Withdrawals-only for staking rewards; inflows are ignored.

As the project matures and moves through its [roadmap](#roadmap), the list of supported features will grow.

# Quality
The code has been tested using a sample of ten thousand randomly-selected stake keys. For 100% of those the reconstructed ADA balance (excluding rewards)
precisely matched the stake recorded in the ledger snapshot produced by Cardano Node. The testing was performed with the slot number 77374448 at the tip of the blockchain. The code of the test is located in [test](test/) directory of this repository.

# Roadmap
The development of the project is organized into the following milestones:
| Milestone | ETA | Status |
| --------- | --- | ------ |
| M1: Show that transaction history can be reconstructed 10x quicker | February 2023 | In progress, On track |
| M2: Analyze the scalability of the Cardano network protocol and prepare requirements for the accelerated one | May 2023 | Planned |
| M3: Full POC of Daedalus Turbo: fast blockchain data delivery and transaction-history reconstruction | February 2024 | Planned |
| M4: Integrate the POC into the official Daedalus builds | January 2025 | Planned |

Due to the experimental nature of the project, the ETAs are tentative.
The development can go both faster and slower than expected.

# Reproducing the benchmarks

Start a new AMD EPYC 7443P instance with Ubuntu 22.04 LTS as the image.
An instance with exactly the same configuration as in the paper can be rented at [Vultr](https://www.vultr.com/products/bare-metal).

create a raid0 disk array and mount it under /data:
```
mdadm --create --verbose /dev/md1 --level=0 --raid-devices=2 /dev/nvme0n1 /dev/nvme1n1
mkfs -t ext4 /dev/md1
mkdir /data
mount /dev/md1 /data
```

install the necessary packages:
```
apt install -y docker-compose
cd /root
git clone https://github.com/scottchiefbaker/dool
cd dool
python3 install.py
/bin/bash <(curl -sL https://deb.nodesource.com/setup_18.x)
apt install -y nodejs
```

copy raw blockchain data from a cardano-node instance:
```
mkdir /data/cardano-node
cp -r /your-cardano-node/immutable /data/cardano-node
```
Note: the benchmarks in the paper were made when the tip of the Cardano blockchain was at the slot number 77374448.

Optional: copy the ledger state from a cardano-node instance - needed only if you plan to benchmark against cardano-wallet:
```
cp -r /your-cardano-node/ledger /data/cardano-node
```

Optional: copy pooldb from a cardano-wallet instance - needed only if you plan to benchmark against cardano-wallet:
```
mkdir /data/cardano-wallet
cp /your-cardano-wallet/stake-pools.sqlite /data/cardano-wallet
```

clone this repository and build the docker image:
```
git clone https://github.com/sierkov/daedalus-turbo dt
cd dt
docker build -t dt -f Dockerfile.test .
```
N.B.: the benchmarks in the paper were made with the version of the code tagged with the "preview-20230104" git tag.

create lz4 compressed copies of all immutabledb chunks:
```
docker run --rm -v /data/cardano-node/immutable:/immutable dt bash -c "sudo chown -R dev:dev /immutable; ./lz4 compress /immutable"
```

run the benchmarks:
```
cd experiments/bench-algo
bash run-bench.sh
```
Expect the bench-algo benchmark to take about three hours when using exactly
the same hardware config.
All experiment data will be saved into log directory next to the run-bench.sh script.

Optionally, run the benchmarks of Cardano Wallet:
```
cd experiments/bench-cardano-wallet
bash run-bench.sh
```
Expect the bench-cardano-wallet benchmark to take about ten hours when using exactly
the same hardware config.
All experiment data will be saved into log directory next to the run-bench.sh script.

# Performance notes
- The performance of the method depends on the speed of your local storage.
  The more cores you have, the higher it should be. The necessary storage
throughput should increase by 250 megabytes/sec for every additional CPU thread.
  So, if you plan to run 20 threads, ensure your SSD can reach 5000 megabytes/sec in the sequential read performance.
- The performance of the method depends on the number of CPU cores you have.
  To fully benefit from the acceleration, benchmarking with 16+ cores is recommended.
- The use of docker volumes can lead to lower performance on some platforms, such as Windows.
  So, when benchmarking to reproduce the paper's results,
  please use exactly the same setup as presented in the paper:
  Ubuntu Linux 22.04 LTS as your host OS.
